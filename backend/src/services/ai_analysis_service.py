"""
AI ê¸°ë°˜ ë§ˆì¼€íŒ… ë¶„ì„ ë³´ê³ ì„œ ì„œë¹„ìŠ¤
GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¨í†¨ë¡œì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ ë³´ê³ ì„œ ìƒì„±
"""
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import anthropic
from loguru import logger
from pydantic import BaseModel

from .snowflake_service import get_snowflake_service
from .ontology_duckdb import ontology_db


class AnalysisRequest(BaseModel):
    """ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    analysis_type: str  # "campaign_performance", "delivery_analysis", "influencer_insights"
    days_back: int = 30
    brand_id: Optional[str] = None
    include_recommendations: bool = True


class AnalysisReport(BaseModel):
    """ë¶„ì„ ë³´ê³ ì„œ ëª¨ë¸"""
    title: str
    analysis_type: str
    generated_at: datetime
    data_period: str
    markdown_content: str
    key_insights: List[str]
    recommendations: List[str]


class AIAnalysisService:
    """AI ê¸°ë°˜ ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """AI ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.claude_client = anthropic.Anthropic(
            api_key=os.getenv("CLAUDE_API_KEY")
        )
        # ì ˆëŒ€ê²½ë¡œë¡œ reports ë””ë ‰í† ë¦¬ ì„¤ì • (backend/src/reports)
        current_file = Path(__file__)
        src_root = current_file.parent.parent  # backend/src/services -> backend/src/
        self.output_dir = src_root / "reports"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("AI ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _build_ontology_context(self) -> str:
        """ì˜¨í†¨ë¡œì§€ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±"""
        try:
            # ì˜¨í†¨ë¡œì§€ ë°ì´í„° ë¡œë“œ
            ontology_db.load_all()
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì¡°íšŒ
            business_rules = ontology_db.get_business_rules()
            rules_context = []
            for rule in business_rules:
                if hasattr(rule, 'name') and hasattr(rule, 'description'):
                    rules_context.append(f"- {rule.name}: {rule.description}")
            
            # ë„ë©”ì¸ê³¼ ê°œë… ì¡°íšŒ
            domains = ontology_db.get_all_domains()
            domain_concepts = {}
            for domain in domains:
                try:
                    concepts_dict = ontology_db.get_domain_concepts(domain)  # Dict[str, DomainConcept] ë°˜í™˜
                    concepts_list = list(concepts_dict.values())  # DomainConcept ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
                    domain_concepts[domain] = [concept.name for concept in concepts_list[:3] if hasattr(concept, 'name')]  # ìƒìœ„ 3ê°œë§Œ
                except Exception as domain_err:
                    logger.warning(f"ë„ë©”ì¸ {domain} ê°œë… ì¡°íšŒ ì‹¤íŒ¨: {domain_err}")
                    domain_concepts[domain] = []
            
            # ë„ë©”ì¸ ê´€ê³„ ì¡°íšŒ
            try:
                relations = list(ontology_db.get_domain_relations())  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                relation_context = []
                for relation in relations[:5]:  # ìƒìœ„ 5ê°œë§Œ
                    if hasattr(relation, 'from_entity') and hasattr(relation, 'to_entity') and hasattr(relation, 'description'):
                        relation_context.append(f"- {relation.from_entity} â†’ {relation.to_entity}: {relation.description}")
            except Exception as rel_err:
                logger.warning(f"ë„ë©”ì¸ ê´€ê³„ ì¡°íšŒ ì‹¤íŒ¨: {rel_err}")
                relation_context = []
            
            # í…Œì´ë¸” ë§¤í•‘ ì •ë³´ ì¡°íšŒ
            try:
                table_mappings = ontology_db.get_all_table_mappings()
                table_context = []
                for domain, mappings in table_mappings.items():
                    if mappings:  # ë§¤í•‘ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ
                        mapping_items = [f"{concept} â†’ {table}" for concept, table in mappings.items()]
                        table_context.append(f"**{domain}**: {', '.join(mapping_items)}")
            except Exception as table_err:
                logger.warning(f"í…Œì´ë¸” ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {table_err}")
                table_context = []
            
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
            rules_section = chr(10).join(rules_context) if rules_context else "- ê¸°ë³¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ì´ ì ìš©ë©ë‹ˆë‹¤"
            domains_section = chr(10).join([f"**{domain}**: {', '.join(concepts)}" for domain, concepts in domain_concepts.items() if concepts]) if domain_concepts else "- ê¸°ë³¸ ë„ë©”ì¸ ê°œë…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"
            tables_section = chr(10).join(table_context) if table_context else "- ê¸°ë³¸ í…Œì´ë¸” ë§¤í•‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"
            relations_section = chr(10).join(relation_context) if relation_context else "- ê¸°ë³¸ ë„ë©”ì¸ ê´€ê³„ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤"
            
            ontology_context = f"""
## F&F ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ë¶„ì„ ê°€ì´ë“œ

### í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë£°
{rules_section}

### ë„ë©”ì¸ë³„ ì£¼ìš” ê°œë…
{domains_section}

### ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ë§¤í•‘
{tables_section}

### ë„ë©”ì¸ ê°„ ê´€ê³„
{relations_section}

### ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­
- ìœ„ ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ì„ ê¸°ë°˜ìœ¼ë¡œ ì„±ê³¼ ì§€í‘œë¥¼ í‰ê°€í•˜ì„¸ìš”
- ê° ë„ë©”ì¸(ë§ˆì¼€íŒ…, ìƒí’ˆ, ë°°ì†¡)ì˜ ì—°ê´€ì„±ì„ ê³ ë ¤í•œ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”
- ì˜¨í†¨ë¡œì§€ì— ì •ì˜ëœ ê´€ê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
"""
            
            return ontology_context
            
        except Exception as e:
            logger.warning(f"ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return """## ê¸°ë³¸ ë¶„ì„ ê°€ì´ë“œ

### ë¶„ì„ ì›ì¹™
- ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”
- ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
- ë§ˆì¼€íŒ…, ìƒí’ˆ, ë°°ì†¡ ë„ë©”ì¸ì˜ ì—°ê´€ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”

### ì£¼ìš” ì„±ê³¼ ì§€í‘œ
- ìº í˜ì¸ ì„±ê³µë¥  ë° ì™„ë£Œìœ¨
- ì¸í”Œë£¨ì–¸ì„œ ì°¸ì—¬ìœ¨ ë° ì½˜í…ì¸  ì—…ë¡œë“œìœ¨
- ë°°ì†¡ ì™„ë£Œìœ¨ ë° ì‹œë”© íš¨ê³¼ì„±
- ë¸Œëœë“œë³„ ìº í˜ì¸ íš¨ìœ¨ì„±
"""

    def _check_business_rule_violations(self, campaigns, campaign_influencers, delivery_entries) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìœ„ë°˜ ìƒí™© ë¶„ì„"""
        try:
            violations = []
            
            # ì»¨í…ì¸  ì—…ë¡œë“œ ì§€ì—° ì²´í¬ (7ì¼ ì´ìƒ ì§€ì—°)
            overdue_content = 0
            for ci in campaign_influencers:
                if ci.get('CAST_STATUS') == 'ACCEPTED' and not ci.get('CONTENTS_POST_DT'):
                    cast_date = ci.get('CAST_MSG_DT')
                    if cast_date and isinstance(cast_date, str):
                        try:
                            cast_dt = datetime.strptime(cast_date, '%Y-%m-%d')
                            if (datetime.now() - cast_dt).days > 7:
                                overdue_content += 1
                        except:
                            pass
            
            if overdue_content > 0:
                violations.append(f"- ì»¨í…ì¸  ì—…ë¡œë“œ ì§€ì—°: {overdue_content}ê±´ (7ì¼ ì´ˆê³¼)")
            
            # ë°°ì†¡ ì§€ì—° ì²´í¬
            overdue_delivery = 0
            for delivery in delivery_entries:
                if delivery.get('STATUS') in ['DELIVERY_IN_PROGRESS', 'READY']:
                    create_date = delivery.get('CREATE_DT')
                    if create_date and isinstance(create_date, str):
                        try:
                            create_dt = datetime.strptime(create_date, '%Y-%m-%d')
                            if (datetime.now() - create_dt).days > 5:
                                overdue_delivery += 1
                        except:
                            pass
            
            if overdue_delivery > 0:
                violations.append(f"- ë°°ì†¡ ì§€ì—°: {overdue_delivery}ê±´ (5ì¼ ì´ˆê³¼)")
            
            # ìº í˜ì¸ ì°¸ì—¬ìœ¨ ì²´í¬
            if campaigns and campaign_influencers:
                participation_rate = len(campaign_influencers) / len(campaigns)
                if participation_rate < 5:  # ìº í˜ì¸ë‹¹ í‰ê·  5ëª… ë¯¸ë§Œ
                    violations.append(f"- ì¸í”Œë£¨ì–¸ì„œ ì°¸ì—¬ìœ¨ ì €ì¡°: ìº í˜ì¸ë‹¹ í‰ê·  {participation_rate:.1f}ëª…")
            
            if violations:
                return "### âš ï¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìœ„ë°˜ ê°ì§€\n" + "\n".join(violations)
            else:
                return "### âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì¤€ìˆ˜ ì–‘í˜¸\n- ì£¼ìš” ìœ„ë°˜ ì‚¬í•­ ì—†ìŒ"
                
        except Exception as e:
            logger.warning(f"ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì²´í¬ ì‹¤íŒ¨: {e}")
            return "### ğŸ“‹ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì²´í¬\n- ì²´í¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ"

    def _call_claude_api(self, prompt: str, max_tokens: int = 4000) -> str:
        """Claude API í˜¸ì¶œ (ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)"""
        try:
            # ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            ontology_context = self._build_ontology_context()
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì˜¨í†¨ë¡œì§€ ì •ë³´ í¬í•¨
            system_message = f"""ë‹¹ì‹ ì€ F&Fì˜ ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

{ontology_context}

ì£¼ì–´ì§„ ë°ì´í„°ì™€ ìœ„ì˜ ì˜¨í†¨ë¡œì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í†µì°°ë ¥ ìˆëŠ” ë¶„ì„ê³¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•˜ì„¸ìš”."""
            
            # Claude API í˜¸ì¶œ
            response = self.claude_client.messages.create(
                model=os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-20241022"),
                max_tokens=max_tokens,
                temperature=0.7,
                system=system_message,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _save_markdown_report(self, content: str, filename: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ íŒŒì¼ ì €ì¥"""
        try:
            file_path = self.output_dir / f"{filename}.md"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            
            logger.info(f"ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_campaign_performance(self, days_back: int = 30, brand_id: str = None, specific_month: str = None) -> AnalysisReport:
        """ìº í˜ì¸ ì„±ê³¼ ë¶„ì„"""
        logger.info(f"ìº í˜ì¸ ì„±ê³¼ ë¶„ì„ ì‹œì‘ - ìµœê·¼ {days_back}ì¼")
        
        try:
            # íŠ¹ì • ì›” ì§€ì •ëœ ê²½ìš° (ì˜ˆ: "2024-07")
            if specific_month:
                logger.info(f"íŠ¹ì • ì›” ë¶„ì„: {specific_month}")
                month_start = datetime.strptime(f"{specific_month}-01", "%Y-%m-%d")
                if month_start.month == 12:
                    month_end = datetime(month_start.year + 1, 1, 1) - timedelta(days=1)
                else:
                    month_end = datetime(month_start.year, month_start.month + 1, 1) - timedelta(days=1)
                
                # íŠ¹ì • ì›” ìº í˜ì¸ ì¡°íšŒ ì¿¼ë¦¬ (ìº í˜ì¸ ê¸°ê°„ì´ í•´ë‹¹ ì›”ê³¼ ê²¹ì¹˜ëŠ” ëª¨ë“  ìº í˜ì¸)
                campaigns_query = f"""
                SELECT id, camp_code, camp_nm, start_date, end_date, status, 
                       target_cnt, brand_id, engmt_avg, engmt_cnt, part_cds, campaign_hashtags
                FROM campaign 
                WHERE (
                    START_DATE BETWEEN '{month_start.strftime('%Y-%m-%d')}' AND '{month_end.strftime('%Y-%m-%d')}'
                    OR END_DATE BETWEEN '{month_start.strftime('%Y-%m-%d')}' AND '{month_end.strftime('%Y-%m-%d')}'
                )
                {f"AND brand_id = '{brand_id}'" if brand_id else ""}
                ORDER BY start_date
                """
                campaigns = get_snowflake_service().execute_query(campaigns_query)
                
                # í•´ë‹¹ ìº í˜ì¸ì˜ ì¸í”Œë£¨ì–¸ì„œë“¤
                if campaigns:
                    campaign_ids = [str(c['id']) for c in campaigns]
                    campaign_ids_str = "', '".join(campaign_ids)
                    
                    influencers_query = f"""
                    SELECT id, cast_msg_dt, cast_status, contents_post_dt, 
                           progress, brand_id, campaign_id, influencer_id
                    FROM campaign_influencer 
                    WHERE campaign_id IN ('{campaign_ids_str}')
                    """
                    campaign_influencers = get_snowflake_service().execute_query(influencers_query)
                    
                    # í•´ë‹¹ ì¸í”Œë£¨ì–¸ì„œë“¤ì˜ ë°°ì†¡
                    if campaign_influencers:
                        influencer_ids = [str(ci['id']) for ci in campaign_influencers]
                        influencer_ids_str = "', '".join(influencer_ids)
                        
                        deliveries_query = f"""
                        SELECT id, create_dt, delivery_confirm_dt, status, 
                               brand_id, campaign_influencer_id, qty, price_total
                        FROM delivery_entry 
                        WHERE campaign_influencer_id IN ('{influencer_ids_str}')
                        """
                        delivery_entries = get_snowflake_service().execute_query(deliveries_query)
                    else:
                        delivery_entries = []
                else:
                    campaign_influencers = []
                    delivery_entries = []
            else:
                # ê¸°ì¡´ ë°©ì‹ (ìµœê·¼ Nì¼)
                campaigns = get_snowflake_service().get_campaigns(active_only=False, brand_id=brand_id)
                campaign_influencers = get_snowflake_service().get_campaign_influencers()
                delivery_entries = get_snowflake_service().get_delivery_entries(
                    date_from=datetime.now() - timedelta(days=days_back)
                )
            
            # ë°ì´í„° ì§‘ê³„
            campaign_stats = self._calculate_campaign_stats(campaigns, campaign_influencers, delivery_entries)
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìœ„ë°˜ ìƒí™© ì²´í¬
            rule_violations = self._check_business_rule_violations(campaigns, campaign_influencers, delivery_entries)
            
            # ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            period_text = f"íŠ¹ì • ì›” ({specific_month})" if specific_month else f"ìµœê·¼ {days_back}ì¼"
            
            prompt = f"""
            F&F ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ìº í˜ì¸ ì§„í–‰ í˜„í™©ì„ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
            
            âš ï¸ ì¤‘ìš”: ë¸Œëœë“œë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì‹¤ì œ ë¸Œëœë“œëª…(MLB, Discovery, Sergio Tacchini ë“±)ì„ ì‚¬ìš©í•˜ê³ , "ë¸Œëœë“œ 1", "ë¸Œëœë“œ 2" ê°™ì€ ìˆ«ìëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”!
            
            ## ë¶„ì„ ë°ì´í„° ê°œìš”
            - ë¶„ì„ ê¸°ê°„: {period_text}
            - ì´ ìº í˜ì¸ ìˆ˜: {len(campaigns)}ê°œ
            - ì´ ì¸í”Œë£¨ì–¸ì„œ ì°¸ì—¬: {len(campaign_influencers)}ëª…
            - ì´ ë°°ì†¡ ê±´ìˆ˜: {len(delivery_entries)}ê±´
            
            ## ìƒì„¸ ì„±ê³¼ í†µê³„
            {json.dumps(campaign_stats, ensure_ascii=False, indent=2)}
            
            ## ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì¤€ìˆ˜ í˜„í™©
            {rule_violations}
            
            ## ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ë¶„ì„ ìš”ì²­ì‚¬í•­
            1. **ë§ˆì¼€íŒ… ë„ë©”ì¸ ì„±ê³¼**: ìº í˜ì¸ ì„±ê³µë¥ , ì°¸ì—¬ìœ¨, ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€
            2. **ìƒí’ˆ-ë§ˆì¼€íŒ… ì—°ê³„**: ë¸Œëœë“œë³„/ì¹´í…Œê³ ë¦¬ë³„ ìº í˜ì¸ íš¨ìœ¨ì„± ë¶„ì„ (ë°˜ë“œì‹œ MLB, Discovery, Sergio Tacchini ë“± ì‹¤ì œ ë¸Œëœë“œëª… ì‚¬ìš©, ë¸Œëœë“œ ìˆ«ì ê¸ˆì§€)
            3. **ë°°ì†¡-ë§ˆì¼€íŒ… í”Œë¡œìš°**: ì‹œë”© ë°°ì†¡ê³¼ ì»¨í…ì¸  ì—…ë¡œë“œ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
            4. **ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìœ„ë°˜**: ì •ì˜ëœ ê·œì¹™ ëŒ€ë¹„ ì‹¤ì œ ì„±ê³¼ ê°­ ë¶„ì„
            5. **ë„ë©”ì¸ ê°„ ê°œì„  ê¸°íšŒ**: ë§ˆì¼€íŒ…â†”ìƒí’ˆâ†”ë°°ì†¡ í”„ë¡œì„¸ìŠ¤ ìµœì í™” ë°©ì•ˆ
            6. **ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­**: ê° ë„ë©”ì¸ ë° ê´€ê³„ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì  ì•¡ì…˜
            
            ## ì‘ì„± ê°€ì´ë“œë¼ì¸
            - ì˜¨í†¨ë¡œì§€ì— ì •ì˜ëœ ë„ë©”ì¸ê³¼ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„
            - ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìœ„ë°˜ ì‚¬í•­ì— ëŒ€í•œ êµ¬ì²´ì  ëŒ€ì‘ ë°©ì•ˆ ì œì‹œ
            - ê° ë„ë©”ì¸(ë§ˆì¼€íŒ…/ìƒí’ˆ/ë°°ì†¡) ì—°ê³„ì„± ê³ ë ¤
            - **ì¤‘ìš”**: ë¸Œëœë“œ ì–¸ê¸‰ ì‹œ ë°˜ë“œì‹œ brand_breakdown_with_namesì˜ ì‹¤ì œ ë¸Œëœë“œëª…(MLB, Discovery, Sergio Tacchini ë“±)ì„ ì‚¬ìš©í•˜ê³ , "ë¸Œëœë“œ 1", "ë¸Œëœë“œ 2" ê°™ì€ ìˆ«ì í‘œê¸°ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
            - Markdown í˜•ì‹, êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ
            - ë°ì´í„° ê¸°ë°˜ì˜ ì •ëŸ‰ì  ì¸ì‚¬ì´íŠ¸
            - **ê°œì„  ë°©ì•ˆì€ ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆ**
            - ì¸ì„¼í‹°ë¸Œ/ë³´ìƒë³´ë‹¤ëŠ” íš¨ê³¼ì ì¸ ì†Œí†µ ë°©ë²•, ì—…ë¡œë“œ ë…ë ¤ ë©”ì‹œì§€, íŒ”ë¡œìš°ì—… ì „ëµì— ì§‘ì¤‘
            - ì˜ˆì‹œ: "ë°°ì†¡ í›„ 3ì¼ì°¨ ë¦¬ë§ˆì¸ë“œ ë©”ì‹œì§€", "ì—…ë¡œë“œ ê°€ì´ë“œ ì œê³µ", "ê°œë³„ ë§ì¶¤ í”¼ë“œë°±", "ë‹¨ê³„ë³„ ì†Œí†µ í”„ë¡œì„¸ìŠ¤" ë“±
            - ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ (ìš°ì„ ìˆœìœ„ í¬í•¨)
            """
            
            # Claude API í˜¸ì¶œ
            markdown_content = self._call_claude_api(prompt)
            
            # ë³´ê³ ì„œ ìƒì„±
            report = AnalysisReport(
                title="ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ìº í˜ì¸ ì„±ê³¼ ë¶„ì„",
                analysis_type="campaign_performance",
                generated_at=datetime.now(),
                data_period=f"ìµœê·¼ {days_back}ì¼",
                markdown_content=markdown_content,
                key_insights=self._extract_insights(markdown_content),
                recommendations=self._extract_recommendations(markdown_content)
            )
            
            # íŒŒì¼ ì €ì¥
            filename = f"campaign_performance_{datetime.now().strftime('%m%d%H%M')}"
            self._save_markdown_report(markdown_content, filename)
            
            return report
            
        except Exception as e:
            logger.error(f"ìº í˜ì¸ ì„±ê³¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_delivery_performance(self, days_back: int = 30) -> AnalysisReport:
        """ë°°ì†¡ ì„±ê³¼ ë¶„ì„"""
        logger.info(f"ë°°ì†¡ ì„±ê³¼ ë¶„ì„ ì‹œì‘ - ìµœê·¼ {days_back}ì¼")
        
        try:
            # ë°°ì†¡ ë°ì´í„° ì¡°íšŒ
            delivery_entries = get_snowflake_service().get_delivery_entries(
                date_from=datetime.now() - timedelta(days=days_back)
            )
            
            # ë°°ì†¡ í†µê³„ ê³„ì‚°
            delivery_stats = self._calculate_delivery_stats(delivery_entries)
            
            prompt = f"""
            F&F ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë°°ì†¡ ì„±ê³¼ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
            
            ## ë¶„ì„ ë°ì´í„°
            - ë¶„ì„ ê¸°ê°„: ìµœê·¼ {days_back}ì¼
            - ì´ ë°°ì†¡ ê±´ìˆ˜: {len(delivery_entries)}
            
            ## ë°°ì†¡ ì„±ê³¼ í†µê³„
            {json.dumps(delivery_stats, ensure_ascii=False, indent=2)}
            
            ## ìš”ì²­ì‚¬í•­
            1. ì „ì²´ ë°°ì†¡ ì„±ê³¼ ìš”ì•½ (ì™„ë£Œìœ¨, í‰ê·  ë°°ì†¡ ì‹œê°„, ì§€ì—°ìœ¨)
            2. ë¸Œëœë“œë³„ ë°°ì†¡ ì„±ê³¼ ë¹„êµ
            3. ë°°ì†¡ ìƒíƒœë³„ í˜„í™© ë¶„ì„
            4. ë°°ì†¡ ì§€ì—° ì›ì¸ ë° íŒ¨í„´ ë¶„ì„
            5. ë°°ì†¡ ê°œì„ ì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­
            
            ## ì‘ì„± ê°€ì´ë“œë¼ì¸
            - Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±
            - ë°ì´í„° ê¸°ë°˜ì˜ ëª…í™•í•œ ë¶„ì„
            - ê°œì„  ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ
            - ìµœëŒ€ 40ì¤„, í•œ ì¤„ë‹¹ ìµœëŒ€ 100ì
            """
            
            markdown_content = self._call_claude_api(prompt)
            
            report = AnalysisReport(
                title="ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë°°ì†¡ ì„±ê³¼ ë¶„ì„",
                analysis_type="delivery_analysis",
                generated_at=datetime.now(),
                data_period=f"ìµœê·¼ {days_back}ì¼",
                markdown_content=markdown_content,
                key_insights=self._extract_insights(markdown_content),
                recommendations=self._extract_recommendations(markdown_content)
            )
            
            filename = f"delivery_analysis_{datetime.now().strftime('%m%d%H%M')}"
            self._save_markdown_report(markdown_content, filename)
            
            return report
            
        except Exception as e:
            logger.error(f"ë°°ì†¡ ì„±ê³¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def analyze_business_rules_impact(self, days_back: int = 30) -> AnalysisReport:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì˜í–¥ë„ ë¶„ì„"""
        logger.info(f"ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì˜í–¥ë„ ë¶„ì„ ì‹œì‘ - ìµœê·¼ {days_back}ì¼")
        
        try:
            # ì˜¨í†¨ë¡œì§€ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì¡°íšŒ
            business_rules = ontology_db.get_business_rules()
            
            # ì‹¤ì œ ë°ì´í„°ë¡œ ë£° ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
            from .rule_engine import rule_engine
            rule_results = rule_engine.execute_rules_with_real_data(days_back=days_back)
            
            # ë£° ì˜í–¥ë„ í†µê³„
            rule_impact_stats = self._calculate_rule_impact_stats(business_rules, rule_results)
            
            prompt = f"""
            F&F ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ì˜ ì˜í–¥ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
            
            ## ë¶„ì„ ë°ì´í„°
            - ë¶„ì„ ê¸°ê°„: ìµœê·¼ {days_back}ì¼
            - ì´ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ìˆ˜: {len(business_rules)}
            - ë£° ì‹¤í–‰ ê²°ê³¼: {len(rule_results)}ê±´
            
            ## ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì •ì˜
            {json.dumps([{"id": r.id, "name": r.name, "priority": r.priority, "description": r.description} for r in business_rules], ensure_ascii=False, indent=2)}
            
            ## ë£° ì˜í–¥ë„ í†µê³„
            {json.dumps(rule_impact_stats, ensure_ascii=False, indent=2)}
            
            ## ìš”ì²­ì‚¬í•­
            1. ê° ë¹„ì¦ˆë‹ˆìŠ¤ ë£°ì˜ íŠ¸ë¦¬ê±° ë¹ˆë„ ë° ì˜í–¥ë„ ë¶„ì„
            2. ìš°ì„ ìˆœìœ„ë³„ ë£° íš¨ê³¼ì„± í‰ê°€
            3. ê°€ì¥ ì¤‘ìš”í•œ ë£°ê³¼ ê°œì„ ì´ í•„ìš”í•œ ë£° ì‹ë³„
            4. ë£° ìµœì í™”ë¥¼ ìœ„í•œ ê¶Œì¥ì‚¬í•­
            5. ì‹ ê·œ ë£° ì œì•ˆ (í•„ìš”í•œ ê²½ìš°)
            
            ## ì‘ì„± ê°€ì´ë“œë¼ì¸
            - Markdown í˜•ì‹ìœ¼ë¡œ ì‘ì„±
            - ê° ë£°ë³„ êµ¬ì²´ì ì¸ ë¶„ì„ ì œê³µ
            - ë°ì´í„° ê¸°ë°˜ ê°œì„  ë°©ì•ˆ ì œì‹œ
            - ìµœëŒ€ 50ì¤„, í•œ ì¤„ë‹¹ ìµœëŒ€ 100ì
            """
            
            markdown_content = self._call_claude_api(prompt)
            
            report = AnalysisReport(
                title="ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì˜í–¥ë„ ë¶„ì„",
                analysis_type="business_rules_impact",
                generated_at=datetime.now(),
                data_period=f"ìµœê·¼ {days_back}ì¼",
                markdown_content=markdown_content,
                key_insights=self._extract_insights(markdown_content),
                recommendations=self._extract_recommendations(markdown_content)
            )
            
            filename = f"business_rules_impact_{datetime.now().strftime('%m%d%H%M')}"
            self._save_markdown_report(markdown_content, filename)
            
            return report
            
        except Exception as e:
            logger.error(f"ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ì˜í–¥ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_brand_mapping(self) -> Dict[str, str]:
        """ë¸Œëœë“œ IDì™€ ë¸Œëœë“œëª… ë§¤í•‘ ì¡°íšŒ"""
        try:
            # brand í…Œì´ë¸”ì—ì„œ ë¸Œëœë“œ ì •ë³´ ì¡°íšŒ
            brands = get_snowflake_service().get_brands()
            brand_mapping = {}
            
            for brand in brands:
                brand_id = str(brand.get('id', ''))  # campaign í…Œì´ë¸”ì˜ brand_id(ë¬¸ìì—´)ì™€ ë§¤ì¹­
                brand_name = brand.get('brand_nm', '')
                if brand_id and brand_name:
                    brand_mapping[brand_id] = brand_name
            
            return brand_mapping
            
        except Exception as e:
            logger.error(f"ë¸Œëœë“œ ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_campaign_stats(self, campaigns: List[Dict], campaign_influencers: List[Dict], deliveries: List[Dict]) -> Dict:
        """ìº í˜ì¸ í†µê³„ ê³„ì‚°"""
        try:
            # ë¸Œëœë“œ ë§¤í•‘ ì •ë³´ ì¡°íšŒ
            brand_mapping = self._get_brand_mapping()
            
            stats = {
                "total_campaigns": len(campaigns),
                "active_campaigns": len([c for c in campaigns if c.get('status') != 'COMPLETE']),
                "total_influencers": len(campaign_influencers),
                "content_upload_rate": 0,
                "delivery_completion_rate": 0,
                "brand_breakdown_with_names": {},
                "status_breakdown": {}
            }
            
            # ì»¨í…ì¸  ì—…ë¡œë“œìœ¨ ê³„ì‚°
            uploaded_count = len([ci for ci in campaign_influencers if ci.get('contents_post_dt')])
            if campaign_influencers:
                stats["content_upload_rate"] = round(uploaded_count / len(campaign_influencers) * 100, 2)
            
            # ë°°ì†¡ ì™„ë£Œìœ¨ ê³„ì‚°
            completed_deliveries = len([d for d in deliveries if d.get('status') == 'COMPLETE'])
            if deliveries:
                stats["delivery_completion_rate"] = round(completed_deliveries / len(deliveries) * 100, 2)
            
            # ë¸Œëœë“œë³„ ë¶„ë¥˜
            for campaign in campaigns:
                brand_id = campaign.get('brand_id', 'Unknown')
                brand_name = brand_mapping.get(brand_id, f"ë¸Œëœë“œ {brand_id}")  # ë§¤í•‘ì´ ì—†ìœ¼ë©´ "ë¸Œëœë“œ ID" í˜•íƒœë¡œ í‘œì‹œ
                
                # ë¸Œëœë“œëª… ê¸°ë°˜ ë¶„ë¥˜ë§Œ ì‚¬ìš©
                if brand_name not in stats["brand_breakdown_with_names"]:
                    stats["brand_breakdown_with_names"][brand_name] = 0
                stats["brand_breakdown_with_names"][brand_name] += 1
            
            # ìƒíƒœë³„ ë¶„ë¥˜
            for campaign in campaigns:
                status = campaign.get('status', 'Unknown')
                if status not in stats["status_breakdown"]:
                    stats["status_breakdown"][status] = 0
                stats["status_breakdown"][status] += 1
            
            return stats
            
        except Exception as e:
            logger.error(f"ìº í˜ì¸ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_delivery_stats(self, deliveries: List[Dict]) -> Dict:
        """ë°°ì†¡ í†µê³„ ê³„ì‚°"""
        try:
            stats = {
                "total_deliveries": len(deliveries),
                "status_breakdown": {},
                "brand_breakdown": {},
                "completion_rate": 0,
                "average_delivery_days": 0
            }
            
            # ìƒíƒœë³„ ë¶„ë¥˜
            for delivery in deliveries:
                status = delivery.get('status', 'Unknown')
                if status not in stats["status_breakdown"]:
                    stats["status_breakdown"][status] = 0
                stats["status_breakdown"][status] += 1
            
            # ë¸Œëœë“œë³„ ë¶„ë¥˜
            for delivery in deliveries:
                brand = delivery.get('brand_id', 'Unknown')
                if brand not in stats["brand_breakdown"]:
                    stats["brand_breakdown"][brand] = 0
                stats["brand_breakdown"][brand] += 1
            
            # ì™„ë£Œìœ¨ ê³„ì‚°
            completed = stats["status_breakdown"].get('COMPLETE', 0)
            if deliveries:
                stats["completion_rate"] = round(completed / len(deliveries) * 100, 2)
            
            return stats
            
        except Exception as e:
            logger.error(f"ë°°ì†¡ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_rule_impact_stats(self, rules: List, rule_results: List) -> Dict:
        """ë£° ì˜í–¥ë„ í†µê³„ ê³„ì‚°"""
        try:
            stats = {
                "total_rules": len(rules),
                "triggered_rules": len([r for r in rule_results if r.triggered]),
                "trigger_rate": 0,
                "priority_breakdown": {},
                "rule_effectiveness": {}
            }
            
            # íŠ¸ë¦¬ê±°ìœ¨ ê³„ì‚°
            if rule_results:
                stats["trigger_rate"] = round(stats["triggered_rules"] / len(rule_results) * 100, 2)
            
            # ìš°ì„ ìˆœìœ„ë³„ ë¶„ë¥˜
            for rule in rules:
                priority = rule.priority
                if priority not in stats["priority_breakdown"]:
                    stats["priority_breakdown"][priority] = {"total": 0, "triggered": 0}
                stats["priority_breakdown"][priority]["total"] += 1
            
            # ë£°ë³„ íš¨ê³¼ì„±
            for result in rule_results:
                if result.triggered:
                    rule_id = result.rule_id
                    if rule_id not in stats["rule_effectiveness"]:
                        stats["rule_effectiveness"][rule_id] = 0
                    stats["rule_effectiveness"][rule_id] += len(result.matched_records)
            
            return stats
            
        except Exception as e:
            logger.error(f"ë£° ì˜í–¥ë„ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}
    
    def _extract_insights(self, markdown_content: str) -> List[str]:
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ì¶”ì¶œ ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        insights = []
        lines = markdown_content.split('\n')
        
        for line in lines:
            if 'ì¸ì‚¬ì´íŠ¸' in line or 'í•µì‹¬' in line or 'ì¤‘ìš”' in line:
                insights.append(line.strip('- ').strip('#').strip())
        
        return insights[:5]  # ìµœëŒ€ 5ê°œ
    
    def _extract_recommendations(self, markdown_content: str) -> List[str]:
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ"""
        recommendations = []
        lines = markdown_content.split('\n')
        
        for line in lines:
            if 'ê¶Œì¥' in line or 'ì¶”ì²œ' in line or 'ì œì•ˆ' in line:
                recommendations.append(line.strip('- ').strip('#').strip())
        
        return recommendations[:5]  # ìµœëŒ€ 5ê°œ


# ì „ì—­ AI ë¶„ì„ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (lazy loading)
ai_analysis_service = None

def get_ai_analysis_service():
    """AI ë¶„ì„ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ lazy loadingìœ¼ë¡œ ë°˜í™˜"""
    global ai_analysis_service
    if ai_analysis_service is None:
        ai_analysis_service = AIAnalysisService()
    return ai_analysis_service
